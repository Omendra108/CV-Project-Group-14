# -*- coding: utf-8 -*-
"""CV_Project_U_net.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DSJf0W1lOcSThDpSRF07sZzSTiiuHUm1

Implementing the CS(Crack Segmentation) network based on the research paper using U-net architecture.
"""

# Install segmentation models PyTorch and kaggle API client
!pip install -q segmentation-models-pytorch
!pip install -q kaggle

# Upload your kaggle.json (Kaggle API token file)
from google.colab import files
files.upload()  # ‚Üê upload your `kaggle.json` here

# Move it to the appropriate config location
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# Download your crack segmentation dataset
# Replace the placeholder below with your actual dataset name from Kaggle
!kaggle datasets download -d omendrakumarupadhyay/crack-segmentation-datasetimage-mask

# Unzip into a folder
!unzip -q '*.zip' -d crack_dataset

import os
import numpy as np
import matplotlib.pyplot as plt
from glob import glob
from sklearn.model_selection import train_test_split
from PIL import Image

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms

import segmentation_models_pytorch as smp
print("Libraries imported successfully !!")

class CrackDataset(Dataset):
    def __init__(self, image_paths, mask_paths, transform=None):
        self.image_paths = image_paths
        self.mask_paths = mask_paths
        self.transform = transform

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        image = Image.open(self.image_paths[idx]).convert('RGB').resize((256, 256))
        mask = Image.open(self.mask_paths[idx]).convert('L').resize((256, 256))

        if self.transform:
            image = self.transform(image)
            mask = self.transform(mask)

        mask = (mask > 0.5).float()  # Binarize mask (0 or 1)
        return image, mask

"""To check if folder exist and print first 2 random image files"""

# Adjust folder names based on dataset structure
image_paths = sorted(glob("/content/crack_dataset/Complete Dataset/images/*.jpg"))
mask_paths = sorted(glob("/content/crack_dataset/Complete Dataset/masks/*.jpg"))


# Train / Val / Test split (80 / 10 / 10)
train_imgs, valtest_imgs, train_masks, valtest_masks = train_test_split(image_paths, mask_paths, test_size=0.2, random_state=42)
val_imgs, test_imgs, val_masks, test_masks = train_test_split(valtest_imgs, valtest_masks, test_size=0.5, random_state=42)

# Define image transform
transform = transforms.Compose([
    transforms.ToTensor(),  # Converts PIL to Tensor and normalizes to [0,1]
])

# Initialize Datasets
train_ds = CrackDataset(train_imgs, train_masks, transform)
val_ds = CrackDataset(val_imgs, val_masks, transform)

# DataLoaders
train_loader = DataLoader(train_ds, batch_size=4, shuffle=True)
val_loader = DataLoader(val_ds, batch_size=4, shuffle=False)

import random

# Choose a random index from the training dataset
random_index = random.randint(0, len(train_ds) - 1)

# Get image and mask pair
image, mask = train_ds[random_index]

# Convert image tensor to NumPy for plotting
image_np = image.permute(1, 2, 0).numpy()  # CHW ‚Üí HWC
mask_np = mask.squeeze().numpy()           # 1xHxW ‚Üí HxW

# Plot the image and mask side by side
plt.figure(figsize=(10, 5))

plt.subplot(1, 2, 1)
plt.imshow(image_np)
plt.title("Crack Image")
plt.axis('off')

plt.subplot(1, 2, 2)
plt.imshow(mask_np, cmap='gray')
plt.title("Segmentation Mask")
plt.axis('off')

plt.tight_layout()
plt.show()

# Use Segmentation Models PyTorch (SMP) to load U-Net with pretrained VGG-16
model = smp.Unet(
    encoder_name="vgg16",        # VGG-16 as encoder
    encoder_weights="imagenet",  # Pretrained on ImageNet
    in_channels=3,               # RGB input
    classes=1,                   # Binary segmentation
    activation=None              # We'll apply sigmoid later manually
).cuda()

class BC_Loss(nn.Module):
    def __init__(self, alpha=0.5, gamma=0.5, eps=1e-7):
        super(BC_Loss, self).__init__()
        self.alpha = alpha
        self.gamma = gamma
        self.eps = eps
        self.bce = nn.BCEWithLogitsLoss(reduction='none')  # Weighted later

    def forward(self, preds, targets):
        preds = torch.sigmoid(preds)  # convert logits to probabilities

        # Approximate Boundary Loss (simple pixel-wise difference)
        boundary_loss = torch.abs(preds - targets).mean()

        # Dice Loss
        intersection = (preds * targets).sum()
        dice_loss = 1 - (2. * intersection + self.eps) / (preds.sum() + targets.sum() + self.eps)

        # Weighted Cross Entropy
        wce = self.bce(preds, targets)
        weights = 1 + 5 * (targets == 1).float()  # Give more weight to crack pixels
        wce_loss = (wce * weights).mean()

        # Combo Loss
        combo_loss = (1 - self.gamma) * dice_loss + self.gamma * wce_loss
        return self.alpha * boundary_loss + (1 - self.alpha) * combo_loss

# Define loss function and optimizer
loss_fn = BC_Loss()
optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)

# üìâ Track training and validation loss
train_losses = []
val_losses = []

# Training and Validation Functions (unchanged)
def train_epoch(loader):
    model.train()
    total_loss = 0
    for images, masks in loader:
        images, masks = images.cuda(), masks.cuda()
        preds = model(images)
        loss = loss_fn(preds, masks)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
    return total_loss / len(loader)

def validate_epoch(loader):
    model.eval()
    total_loss = 0
    with torch.no_grad():
        for images, masks in loader:
            images, masks = images.cuda(), masks.cuda()
            preds = model(images)
            loss = loss_fn(preds, masks)
            total_loss += loss.item()
    return total_loss / len(loader)

# üß† Training Loop
epochs = 25  # Set your desired number of epochs
for epoch in range(epochs):
    train_loss = train_epoch(train_loader)
    val_loss = validate_epoch(val_loader)

    train_losses.append(train_loss)
    val_losses.append(val_loss)

    print(f"üìÜ Epoch {epoch+1}/{epochs} ‚Äî Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}")

"""Splitting test, train and validation dataset"""

# ‚úÖ Define the test dataset and loader
test_ds = CrackDataset(test_imgs, test_masks, transform)
test_loader = DataLoader(test_ds, batch_size=1, shuffle=False)

import matplotlib.pyplot as plt
from sklearn.metrics import precision_score, recall_score, f1_score, jaccard_score
import numpy as np

# -----------------------------------------------------------------------------------
# üìà Plot Training and Validation Loss
# -----------------------------------------------------------------------------------
plt.figure(figsize=(10, 5))
plt.plot(train_losses, label='Train Loss', color='blue', linewidth=2)
plt.plot(val_losses, label='Validation Loss', color='orange', linewidth=2)
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training vs Validation Loss')
plt.legend()
plt.grid(True, linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

# -----------------------------------------------------------------------------------
# üìä Compute Segmentation Metrics on Test Set
# -----------------------------------------------------------------------------------
def evaluate_metrics(model, dataloader, threshold=0.5):
    model.eval()
    iou_list, precision_list, recall_list, f1_list = [], [], [], []

    with torch.no_grad():
        for images, masks in dataloader:
            images = images.cuda()
            masks = masks.cuda()

            preds = model(images)
            preds = torch.sigmoid(preds)
            preds = (preds > threshold).float()

            preds_flat = preds.view(-1).cpu().numpy()
            masks_flat = masks.view(-1).cpu().numpy()

            iou = jaccard_score(masks_flat, preds_flat, zero_division=0)
            precision = precision_score(masks_flat, preds_flat, zero_division=0)
            recall = recall_score(masks_flat, preds_flat, zero_division=0)
            f1 = f1_score(masks_flat, preds_flat, zero_division=0)

            iou_list.append(iou)
            precision_list.append(precision)
            recall_list.append(recall)
            f1_list.append(f1)

    avg_iou = np.mean(iou_list)
    avg_precision = np.mean(precision_list)
    avg_recall = np.mean(recall_list)
    avg_f1 = np.mean(f1_list)

    print("\nüìä Test Set Metrics:")
    print(f"IoU (Jaccard):  {avg_iou:.4f}")
    print(f"Precision:      {avg_precision:.4f}")
    print(f"Recall:         {avg_recall:.4f}")
    print(f"F1 Score:       {avg_f1:.4f}")

    return avg_iou, avg_precision, avg_recall, avg_f1

# üîç Run Evaluation on Test Set
avg_iou, avg_precision, avg_recall, avg_f1 = evaluate_metrics(model, test_loader)

# -----------------------------------------------------------------------------------
# üìà Plot Segmentation Metrics as a Bar Chart
# -----------------------------------------------------------------------------------
metrics = [avg_iou, avg_precision, avg_recall, avg_f1]
labels = ['IoU', 'Precision', 'Recall', 'F1 Score']
colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']

plt.figure(figsize=(8, 5))
bars = plt.bar(labels, metrics, color=colors)
plt.ylim(0, 1)
plt.title("Segmentation Metrics on Test Set")
plt.ylabel("Score")

# Annotate values
for bar in bars:
    height = bar.get_height()
    plt.text(bar.get_x() + bar.get_width() / 2., height + 0.02, f'{height:.2f}', ha='center', fontsize=12)

plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

# üß™ Visualize predictions from test set
test_ds = CrackDataset(test_imgs, test_masks, transform)
test_loader = DataLoader(test_ds, batch_size=1, shuffle=True)

def visualize_test_prediction(index=0):
    model.eval()
    image, mask = test_ds[index]
    with torch.no_grad():
        pred = torch.sigmoid(model(image.unsqueeze(0).cuda()))[0][0].cpu().numpy()

    image_np = image.permute(1, 2, 0).numpy()
    mask_np = mask.squeeze().numpy()

    plt.figure(figsize=(15, 5))
    plt.subplot(1, 3, 1)
    plt.imshow(image_np)
    plt.title("Input Image")
    plt.axis('off')

    plt.subplot(1, 3, 2)
    plt.imshow(mask_np, cmap='gray')
    plt.title("Ground Truth Mask")
    plt.axis('off')

    plt.subplot(1, 3, 3)
    plt.imshow(pred > 0.5, cmap='gray')
    plt.title("Predicted Mask")
    plt.axis('off')

    plt.tight_layout()
    plt.show()

# üëá Try different indices
visualize_test_prediction(index=3)

# üì§ Upload your own image to segment
from google.colab import files
uploaded = files.upload()

# üñºÔ∏è Predict crack segmentation on uploaded image
from PIL import Image

uploaded_path = list(uploaded.keys())[0]
model.eval()

# Load and preprocess image
input_image = Image.open(uploaded_path).convert('RGB').resize((256, 256))
input_tensor = transform(input_image).unsqueeze(0).cuda()

# Predict
with torch.no_grad():
    prediction = torch.sigmoid(model(input_tensor))[0][0].cpu().numpy()

# Plot result
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.imshow(input_image)
plt.title("Uploaded Input Image")
plt.axis('off')

plt.subplot(1, 2, 2)
plt.imshow(prediction > 0.5, cmap='gray')
plt.title("Predicted Crack Mask")
plt.axis('off')

plt.tight_layout()
plt.show()

from google.colab import drive
drive.mount('/content/drive')

# Define path to save the model inside your Colab Notebooks folder on Drive
model_save_path = "/content/drive/MyDrive/Colab Notebooks/crack_segmentation_model_U-net_2.pth"

# Save the model
torch.save(model.state_dict(), model_save_path)

print(f"‚úÖ Model saved at: {model_save_path}")